{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libreria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jamr1\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\jamr1\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "C:\\Users\\jamr1\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scikitplot\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU, Activation\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6176, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>id_img</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy</td>\n",
       "      <td>22373</td>\n",
       "      <td>happy/22373.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy</td>\n",
       "      <td>21433</td>\n",
       "      <td>happy/21433.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happy</td>\n",
       "      <td>12418</td>\n",
       "      <td>happy/12418.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>21278</td>\n",
       "      <td>happy/21278.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>happy</td>\n",
       "      <td>8081</td>\n",
       "      <td>happy/08081.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  id_img             path\n",
       "0  happy   22373  happy/22373.jpg\n",
       "1  happy   21433  happy/21433.jpg\n",
       "2  happy   12418  happy/12418.jpg\n",
       "3  happy   21278  happy/21278.jpg\n",
       "4  happy    8081  happy/08081.jpg"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train_set.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy</td>\n",
       "      <td>[[25, 44, 56, 68, 88, 98, 93, 92, 105, 120, 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy</td>\n",
       "      <td>[[33, 29, 22, 18, 19, 23, 22, 19, 20, 23, 14, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happy</td>\n",
       "      <td>[[35, 43, 66, 84, 71, 41, 36, 53, 97, 56, 100,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>[[118, 124, 132, 126, 127, 139, 67, 38, 33, 29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>happy</td>\n",
       "      <td>[[201, 209, 193, 107, 106, 107, 98, 114, 144, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              array\n",
       "0  happy  [[25, 44, 56, 68, 88, 98, 93, 92, 105, 120, 13...\n",
       "1  happy  [[33, 29, 22, 18, 19, 23, 22, 19, 20, 23, 14, ...\n",
       "2  happy  [[35, 43, 66, 84, 71, 41, 36, 53, 97, 56, 100,...\n",
       "3  happy  [[118, 124, 132, 126, 127, 139, 67, 38, 33, 29...\n",
       "4  happy  [[201, 209, 193, 107, 106, 107, 98, 114, 144, ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['path']\n",
    "df['array'] = df['path'].apply(lambda x: cv2.imread((\"train/\" + x),cv2.IMREAD_GRAYSCALE))\n",
    "df = df[['label', 'array']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4117, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_img</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18341</td>\n",
       "      <td>test/18341.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13176</td>\n",
       "      <td>test/13176.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23945</td>\n",
       "      <td>test/23945.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15968</td>\n",
       "      <td>test/15968.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18382</td>\n",
       "      <td>test/18382.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_img            path\n",
       "0   18341  test/18341.jpg\n",
       "1   13176  test/13176.jpg\n",
       "2   23945  test/23945.jpg\n",
       "3   15968  test/15968.jpg\n",
       "4   18382  test/18382.jpg"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test_set.csv')\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[124, 69, 19, 5, 8, 9, 18, 34, 23, 4, 0, 2, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[7, 3, 2, 5, 5, 2, 2, 5, 46, 35, 37, 37, 19, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[88, 78, 136, 145, 128, 75, 203, 130, 178, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[254, 255, 255, 255, 254, 254, 254, 255, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[9, 2, 8, 25, 12, 55, 143, 140, 89, 70, 56, 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               array\n",
       "0  [[124, 69, 19, 5, 8, 9, 18, 34, 23, 4, 0, 2, 7...\n",
       "1  [[7, 3, 2, 5, 5, 2, 2, 5, 46, 35, 37, 37, 19, ...\n",
       "2  [[88, 78, 136, 145, 128, 75, 203, 130, 178, 14...\n",
       "3  [[254, 255, 255, 255, 254, 254, 254, 255, 255,...\n",
       "4  [[9, 2, 8, 25, 12, 55, 143, 140, 89, 70, 56, 6..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['path']\n",
    "test['array'] = test['path'].apply(lambda x: cv2.imread((x),cv2.IMREAD_GRAYSCALE))\n",
    "test = test[['array']]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happy      3285\n",
       "sadness    2891\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_size = 48\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixels_to_array(pixels):\n",
    "    array = np.array(pixels,'float64')\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_reshape(data):\n",
    "    image = np.reshape(data['pixels'].to_list(),(data.shape[0],48,48,1))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pixels'] = df['array'].apply(pixels_to_array)\n",
    "X = image_reshape(df)\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5558, 48, 48, 1), (618, 48, 48, 1), (5558,), (618,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
    "                                                    shuffle=True, stratify=y,\n",
    "                                                    test_size=0.1, random_state=42)\n",
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.\n",
    "X_valid = X_valid / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_net(optim, num_classes, srhink_factor = 1):\n",
    "    \"\"\"\n",
    "    This is a Deep Convolutional Neural Network (DCNN). For generalization purpose I used dropouts in regular intervals.\n",
    "    I used `ELU` as the activation because it avoids dying relu problem but also performed well as compared to LeakyRelu\n",
    "    atleast in this case. `he_normal` kernel initializer is used as it suits ELU. BatchNormalization is also used for better\n",
    "    results.\n",
    "    \"\"\"\n",
    "    net = Sequential(name='DCNN')\n",
    "\n",
    "    net.add(\n",
    "        Conv2D(\n",
    "            filters= int(srhink_factor*64),\n",
    "            kernel_size=(4,4),\n",
    "            input_shape=(48, 48, 1),\n",
    "            activation='elu',\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal',\n",
    "            name='conv2d_1'\n",
    "        )\n",
    "    )\n",
    "    net.add(BatchNormalization(name='batchnorm_1'))\n",
    "    net.add(\n",
    "        Conv2D(\n",
    "            filters=int(srhink_factor*64),\n",
    "            kernel_size=(4,4),\n",
    "            activation='elu',\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal',\n",
    "            name='conv2d_2'\n",
    "        )\n",
    "    )\n",
    "    net.add(BatchNormalization(name='batchnorm_2'))\n",
    "    \n",
    "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_1'))\n",
    "    net.add(Dropout(0.1, name='dropout_1'))\n",
    "\n",
    "    net.add(\n",
    "        Conv2D(\n",
    "            filters=int(srhink_factor*128),\n",
    "            kernel_size=(3,3),\n",
    "            activation='elu',\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal',\n",
    "            name='conv2d_3'\n",
    "        )\n",
    "    )\n",
    "    net.add(BatchNormalization(name='batchnorm_3'))\n",
    "    net.add(\n",
    "        Conv2D(\n",
    "            filters=int(srhink_factor*128),\n",
    "            kernel_size=(3,3),\n",
    "            activation='elu',\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal',\n",
    "            name='conv2d_4'\n",
    "        )\n",
    "    )\n",
    "    net.add(BatchNormalization(name='batchnorm_4'))\n",
    "    \n",
    "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_2'))\n",
    "    net.add(Dropout(0.1, name='dropout_2'))\n",
    "\n",
    "    net.add(\n",
    "        Conv2D(\n",
    "            filters=int(srhink_factor*128),\n",
    "            kernel_size=(3,3),\n",
    "            activation='elu',\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal',\n",
    "            name='conv2d_5'\n",
    "        )\n",
    "    )\n",
    "    net.add(BatchNormalization(name='batchnorm_5'))\n",
    "    net.add(\n",
    "        Conv2D(\n",
    "            filters=int(srhink_factor*256),\n",
    "            kernel_size=(3,3),\n",
    "            activation='elu',\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal',\n",
    "            name='conv2d_6'\n",
    "        )\n",
    "    )\n",
    "    net.add(BatchNormalization(name='batchnorm_6'))\n",
    "    \n",
    "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_3'))\n",
    "    net.add(Dropout(0.1, name='dropout_3'))\n",
    "\n",
    "    net.add(Flatten(name='flatten'))\n",
    "        \n",
    "    net.add(\n",
    "        Dense(\n",
    "            128,\n",
    "            activation='elu',\n",
    "            kernel_initializer='he_normal',\n",
    "            name='dense_1'\n",
    "        )\n",
    "    )\n",
    "    net.add(BatchNormalization(name='batchnorm_7'))\n",
    "    \n",
    "    net.add(Dropout(0.1, name='dropout_4'))\n",
    "    \n",
    "    net.add(\n",
    "        Dense(\n",
    "            128,\n",
    "            activation='elu',\n",
    "            kernel_initializer='he_normal',\n",
    "            name='dense_2'\n",
    "        )\n",
    "    )\n",
    "    net.add(BatchNormalization(name='batchnorm_8'))\n",
    "    \n",
    "    net.add(Dropout(0.1, name='dropout_5'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    net.add(\n",
    "        Dense(\n",
    "            num_classes,\n",
    "            activation='softmax',\n",
    "            name='out_layer'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    net.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=optim,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    net.summary()\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I used two callbacks one is `early stopping` for avoiding overfitting training data\n",
    "and other `ReduceLROnPlateau` for learning rate.\n",
    "\"\"\"\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0.00005,\n",
    "    patience=11,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=7,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    early_stopping,\n",
    "    lr_scheduler,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "train_datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_net2(optim, num_classes):\n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu',kernel_regularizer=regularizers.l2(0.0001),input_shape=(48,48,1)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(7, kernel_size=(1, 1), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "    # # model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(7, kernel_size=(4, 4), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "    # model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',optimizer=optim,metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DCNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 48, 48, 64)        1088      \n",
      "                                                                 \n",
      " batchnorm_1 (BatchNormaliza  (None, 48, 48, 64)       256       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 48, 48, 64)        65600     \n",
      "                                                                 \n",
      " batchnorm_2 (BatchNormaliza  (None, 48, 48, 64)       256       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " maxpool2d_1 (MaxPooling2D)  (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " batchnorm_3 (BatchNormaliza  (None, 24, 24, 128)      512       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " batchnorm_4 (BatchNormaliza  (None, 24, 24, 128)      512       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " maxpool2d_2 (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 12, 12, 128)       147584    \n",
      "                                                                 \n",
      " batchnorm_5 (BatchNormaliza  (None, 12, 12, 128)      512       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " batchnorm_6 (BatchNormaliza  (None, 12, 12, 256)      1024      \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " maxpool2d_3 (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               1179776   \n",
      "                                                                 \n",
      " batchnorm_7 (BatchNormaliza  (None, 128)              512       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " batchnorm_8 (BatchNormaliza  (None, 128)              512       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " out_layer (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,931,522\n",
      "Trainable params: 1,929,474\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002AF8C09B438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002AF8C09B438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jamr1\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shapes (None, 1) and (None, 2) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19916/823438155.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2151\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2153\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   2154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2155\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[1;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[0;32m   5004\u001b[0m   \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5005\u001b[0m   \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5006\u001b[1;33m   \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5008\u001b[0m   \u001b[1;31m# Use logits whenever they are available. `softmax` and `sigmoid`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes (None, 1) and (None, 2) are incompatible"
     ]
    }
   ],
   "source": [
    "batch_size = 32 #batch size of 32 performs the best.\n",
    "epochs = 20\n",
    "optims = [\n",
    "    optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name='Nadam'),\n",
    "    optimizers.SGD(learning_rate = 0.0001, momentum=0.9, nesterov=False, name=\"SGD\"),\n",
    "    optimizers.Adam(0.001),\n",
    "    \n",
    "]\n",
    "\n",
    "# I tried both `Nadam` and `Adam`, the difference in results is not different but I finally went with Nadam as it is more popular.\n",
    "model = build_net(optims[0], 2, 1) \n",
    "history = model.fit_generator(\n",
    "    train_datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    steps_per_epoch=len(X_train) / batch_size ,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    use_multiprocessing=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "129c28eb7371f81f3b772b69408a02d1e141a0d5c957c78df09fa0d1b2bc4f41"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
