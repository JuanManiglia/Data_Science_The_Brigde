{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import cv2 # opencv-python, librería de referencia para tratamiento de imagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://img.devrant.com/devrant/rant/r_1688469_xaXLS.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>id_img</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy</td>\n",
       "      <td>22373</td>\n",
       "      <td>happy/22373.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy</td>\n",
       "      <td>21433</td>\n",
       "      <td>happy/21433.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happy</td>\n",
       "      <td>12418</td>\n",
       "      <td>happy/12418.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>21278</td>\n",
       "      <td>happy/21278.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>happy</td>\n",
       "      <td>8081</td>\n",
       "      <td>happy/08081.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6171</th>\n",
       "      <td>sadness</td>\n",
       "      <td>11346</td>\n",
       "      <td>sadness/11346.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6172</th>\n",
       "      <td>sadness</td>\n",
       "      <td>4441</td>\n",
       "      <td>sadness/04441.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6173</th>\n",
       "      <td>sadness</td>\n",
       "      <td>15236</td>\n",
       "      <td>sadness/15236.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6174</th>\n",
       "      <td>sadness</td>\n",
       "      <td>27361</td>\n",
       "      <td>sadness/27361.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6175</th>\n",
       "      <td>sadness</td>\n",
       "      <td>25239</td>\n",
       "      <td>sadness/25239.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6176 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label  id_img               path\n",
       "0       happy   22373    happy/22373.jpg\n",
       "1       happy   21433    happy/21433.jpg\n",
       "2       happy   12418    happy/12418.jpg\n",
       "3       happy   21278    happy/21278.jpg\n",
       "4       happy    8081    happy/08081.jpg\n",
       "...       ...     ...                ...\n",
       "6171  sadness   11346  sadness/11346.jpg\n",
       "6172  sadness    4441  sadness/04441.jpg\n",
       "6173  sadness   15236  sadness/15236.jpg\n",
       "6174  sadness   27361  sadness/27361.jpg\n",
       "6175  sadness   25239  sadness/25239.jpg\n",
       "\n",
       "[6176 rows x 3 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.read_csv(\"train_set.csv\")\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         happy/22373.jpg\n",
       "1         happy/21433.jpg\n",
       "2         happy/12418.jpg\n",
       "3         happy/21278.jpg\n",
       "4         happy/08081.jpg\n",
       "              ...        \n",
       "6171    sadness/11346.jpg\n",
       "6172    sadness/04441.jpg\n",
       "6173    sadness/15236.jpg\n",
       "6174    sadness/27361.jpg\n",
       "6175    sadness/25239.jpg\n",
       "Name: path, Length: 6176, dtype: object"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['array'] = train_set['path'].apply(lambda x: cv2.imread((\"train/\" + x),cv2.IMREAD_GRAYSCALE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>id_img</th>\n",
       "      <th>path</th>\n",
       "      <th>array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy</td>\n",
       "      <td>22373</td>\n",
       "      <td>happy/22373.jpg</td>\n",
       "      <td>[[25, 44, 56, 68, 88, 98, 93, 92, 105, 120, 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy</td>\n",
       "      <td>21433</td>\n",
       "      <td>happy/21433.jpg</td>\n",
       "      <td>[[33, 29, 22, 18, 19, 23, 22, 19, 20, 23, 14, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happy</td>\n",
       "      <td>12418</td>\n",
       "      <td>happy/12418.jpg</td>\n",
       "      <td>[[35, 43, 66, 84, 71, 41, 36, 53, 97, 56, 100,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>21278</td>\n",
       "      <td>happy/21278.jpg</td>\n",
       "      <td>[[118, 124, 132, 126, 127, 139, 67, 38, 33, 29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>happy</td>\n",
       "      <td>8081</td>\n",
       "      <td>happy/08081.jpg</td>\n",
       "      <td>[[201, 209, 193, 107, 106, 107, 98, 114, 144, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6171</th>\n",
       "      <td>sadness</td>\n",
       "      <td>11346</td>\n",
       "      <td>sadness/11346.jpg</td>\n",
       "      <td>[[167, 180, 196, 171, 101, 50, 52, 70, 55, 49,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6172</th>\n",
       "      <td>sadness</td>\n",
       "      <td>4441</td>\n",
       "      <td>sadness/04441.jpg</td>\n",
       "      <td>[[163, 154, 128, 116, 121, 106, 90, 99, 115, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6173</th>\n",
       "      <td>sadness</td>\n",
       "      <td>15236</td>\n",
       "      <td>sadness/15236.jpg</td>\n",
       "      <td>[[109, 25, 29, 33, 55, 65, 82, 87, 147, 179, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6174</th>\n",
       "      <td>sadness</td>\n",
       "      <td>27361</td>\n",
       "      <td>sadness/27361.jpg</td>\n",
       "      <td>[[62, 64, 67, 52, 57, 65, 50, 55, 117, 179, 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6175</th>\n",
       "      <td>sadness</td>\n",
       "      <td>25239</td>\n",
       "      <td>sadness/25239.jpg</td>\n",
       "      <td>[[163, 167, 123, 78, 50, 30, 26, 14, 7, 12, 50...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6176 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label  id_img               path  \\\n",
       "0       happy   22373    happy/22373.jpg   \n",
       "1       happy   21433    happy/21433.jpg   \n",
       "2       happy   12418    happy/12418.jpg   \n",
       "3       happy   21278    happy/21278.jpg   \n",
       "4       happy    8081    happy/08081.jpg   \n",
       "...       ...     ...                ...   \n",
       "6171  sadness   11346  sadness/11346.jpg   \n",
       "6172  sadness    4441  sadness/04441.jpg   \n",
       "6173  sadness   15236  sadness/15236.jpg   \n",
       "6174  sadness   27361  sadness/27361.jpg   \n",
       "6175  sadness   25239  sadness/25239.jpg   \n",
       "\n",
       "                                                  array  \n",
       "0     [[25, 44, 56, 68, 88, 98, 93, 92, 105, 120, 13...  \n",
       "1     [[33, 29, 22, 18, 19, 23, 22, 19, 20, 23, 14, ...  \n",
       "2     [[35, 43, 66, 84, 71, 41, 36, 53, 97, 56, 100,...  \n",
       "3     [[118, 124, 132, 126, 127, 139, 67, 38, 33, 29...  \n",
       "4     [[201, 209, 193, 107, 106, 107, 98, 114, 144, ...  \n",
       "...                                                 ...  \n",
       "6171  [[167, 180, 196, 171, 101, 50, 52, 70, 55, 49,...  \n",
       "6172  [[163, 154, 128, 116, 121, 106, 90, 99, 115, 1...  \n",
       "6173  [[109, 25, 29, 33, 55, 65, 82, 87, 147, 179, 1...  \n",
       "6174  [[62, 64, 67, 52, 57, 65, 50, 55, 117, 179, 15...  \n",
       "6175  [[163, 167, 123, 78, 50, 30, 26, 14, 7, 12, 50...  \n",
       "\n",
       "[6176 rows x 4 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las imágenes están en blanco y negro, pero el método `cv2.imread` necesita que se le especifique el segundo argumento como 0 ya que por defecto leerá en color. \n",
    "\n",
    "`flag: It specifies the way in which image should be read. It’s default value is cv2.IMREAD_COLOR`\n",
    "[para más info...](https://www.geeksforgeeks.org/python-opencv-cv2-imread-method/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 25,  44,  56, ...,  34,  11,  17],\n",
       "       [ 30,  46,  54, ...,  45,  19,  17],\n",
       "       [ 38,  50,  55, ...,  53,  25,  12],\n",
       "       ...,\n",
       "       [110, 116, 129, ...,  40,  63,  34],\n",
       "       [110, 138, 135, ...,  51,  52,  30],\n",
       "       [ 93, 142, 127, ...,  73,  48,  33]], dtype=uint8)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drama = cv2.imread(\"train/\" + train_set.path[0], 0) \n",
    "drama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2d288675048>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(drama, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drama.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ten en cuenta que las imágenes no están mezcladas, están primero las fotos felices y luego todas las fotos tristes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
       "            ...\n",
       "            3275, 3276, 3277, 3278, 3279, 3280, 3281, 3282, 3283, 3284],\n",
       "           dtype='int64', length=3285)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[train_set.label == \"happy\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([3285, 3286, 3287, 3288, 3289, 3290, 3291, 3292, 3293, 3294,\n",
       "            ...\n",
       "            6166, 6167, 6168, 6169, 6170, 6171, 6172, 6173, 6174, 6175],\n",
       "           dtype='int64', length=2891)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[train_set.label == \"sadness\"].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accedemos a las imágenes directamente en sus carpetas, puedes usar librerías como `glob` o nuestro ya viejo conocido, `os`.\n",
    "Para cargar y mostrar las imágenes `imageio` o como ya hemos visto `cv2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer** Para gestionar imágenes no es necesario cargar los arrays en nuestro jupyter. \n",
    "\n",
    "https://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_set.drop(['label','path','id_img'],axis=1)\n",
    "y = train_set['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-200:]\n",
    "y_val = y_train[-200:]\n",
    "\n",
    "X_train = X_train[:-200]\n",
    "y_train = y_train[:-200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Flatten(input_shape=(48,48)))\n",
    "model.add(keras.layers.Dense(units=300, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=150, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=50, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=1, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 300)               691500    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 150)               45150     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 50)                7550      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 744,251\n",
      "Trainable params: 744,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21036/1441892226.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,batch_size=120,epochs=20, validation_data=(X_val,y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
